{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY_SELF\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import Tools\n",
    "\n",
    "tools = Tools()\n",
    "tool_dict = tools.tool_dict\n",
    "\n",
    "print(\"This app is using the following tool:\")\n",
    "for tool in tool_dict:\n",
    "    print(tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Agent Parameter (yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# ! 注意yaml檔案版本\n",
    "with open('agents_parameter.yaml', 'r', encoding=\"utf-8\") as file:\n",
    "    agents_parameter = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    \"\"\"Plan to follow in future\"\"\"\n",
    "\n",
    "    steps: List[str] = Field(\n",
    "        description=\"different steps to follow, should be in sorted order\"\n",
    "    )\n",
    "\n",
    "planner_llm_config = agents_parameter[\"Planner\"][\"llm_config\"]\n",
    "planner_system_prompt = agents_parameter[\"Planner\"][\"prompt\"]\n",
    "\n",
    "planner_llm = ChatOpenAI(model=planner_llm_config[\"model\"], temperature=planner_llm_config[\"temperature\"])\n",
    "planner_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", planner_system_prompt),\n",
    "        (\"placeholder\", \"{user_input}\"), # placeholer 用來動態嵌入使用者輸入的訊息\n",
    "    ]\n",
    ")\n",
    "\n",
    "planner = planner_prompt | planner_llm.with_structured_output(Plan) # 限制使用特定模板回答問題\n",
    "\n",
    "print(\"planner_llm_config:\")\n",
    "for key, value in planner_llm_config.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(\"planner_system_prompt: \\n\" + planner_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = planner.invoke({\"user_input\": [(\"user\", \"Summarize the content of the 111 Academic Affairs Regulations.\")]})\n",
    "# for step in response.steps:\n",
    "#     print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = planner.invoke({\"user_input\": [(\"user\", \"Please help me fill out the leave application on the school website.\")]})\n",
    "# for step in response.steps:\n",
    "#     print(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import create_react_agent_with_yaml\n",
    "\n",
    "executor = create_react_agent_with_yaml(\"Executor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = executor.invoke({\"messages\": [(\"user\", \"Who is the headmaster of National Central University in Taiwan?\")]})\n",
    "for message in response[\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = executor.invoke({\"messages\": [(\"user\", \"Please help me fill out the leave application on https://cis.ncu.edu.tw/iNCU/stdAffair/leaveRequest.\")]})\n",
    "# for message in response[\"messages\"]:\n",
    "#     print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "class Response(BaseModel):\n",
    "    \"\"\"Response to user.\"\"\"\n",
    "\n",
    "    response: str\n",
    "\n",
    "\n",
    "class Act(BaseModel):\n",
    "    \"\"\"Action to perform.\"\"\"\n",
    "\n",
    "    action: Union[Response, Plan] = Field(\n",
    "        description=\"Action to perform. If you want to respond to user, use Response.\"\n",
    "        \"If you need to further use tools to get the answer, use Plan.\"\n",
    "    )\n",
    "\n",
    "replanner_model = agents_parameter[\"Replanner\"][\"model\"]\n",
    "replanner_system_prompt = f\"{agents_parameter['Replanner']['prompt']}\"\n",
    "\n",
    "replanner_llm = ChatOpenAI(model=replanner_model) # ! Replanner需要使用gpt-4o才不會一直call tools\n",
    "replanner_prompt = ChatPromptTemplate.from_template(replanner_system_prompt)\n",
    "\n",
    "replanner = replanner_prompt | replanner_llm.with_structured_output(Act) # 限制使用特定模板回答問題\n",
    "\n",
    "print(\"replanner_model: \" + replanner_model)\n",
    "print(\"replanner_prompt: \\n\" + replanner_system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_model = agents_parameter[\"Solver\"][\"model\"]\n",
    "solver_system_prompt = agents_parameter[\"Solver\"][\"prompt\"]\n",
    "\n",
    "solver_llm = ChatOpenAI(model=solver_model)\n",
    "solver_prompt = ChatPromptTemplate.from_template(solver_system_prompt)\n",
    "\n",
    "solver = solver_prompt | solver_llm\n",
    "\n",
    "print(\"solver_model: \" + solver_model)\n",
    "print(\"solver_system_prompt: \\n\" + solver_system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Graph State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, Tuple, Any\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class PlanExecute(TypedDict):\n",
    "    input: str\n",
    "    plan: List[str]\n",
    "    past_steps: Annotated[List[Tuple], operator.add]\n",
    "    response: str\n",
    "    history: List[Tuple[str, Any]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agent Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def plan_step(state: PlanExecute):\n",
    "    plan = await planner.ainvoke({\"user_input\": [(\"user\", state[\"input\"])]}) # 對應到planner system prompt中的{user_input}\n",
    "    state[\"history\"].append((\"Planner\", plan.steps)) # 將plan的步驟加入history中\n",
    "\n",
    "    return {\n",
    "        \"plan\": plan.steps,\n",
    "        \"history\": state[\"history\"],\n",
    "    }\n",
    "\n",
    "async def execute_step(state: PlanExecute):\n",
    "    plan = state[\"plan\"]\n",
    "    plan_str = \"\\n\".join(f\"{i+1}. {step}\" for i, step in enumerate(plan))\n",
    "    task = plan[0]\n",
    "    task_formatted = f\"\"\"For the following plan:\n",
    "{plan_str}\\n\\nYou are tasked with executing step {1}, {task}.\"\"\"\n",
    "    agent_response = await executor.ainvoke({\"messages\": [(\"user\", task_formatted)]}) # react agent 用 messages 方式接收訊息\n",
    "    state[\"history\"].append((\"Executor\", (task, agent_response[\"messages\"][-1].content)))\n",
    "\n",
    "    return {\n",
    "        \"past_steps\": [(task, agent_response[\"messages\"][-1].content)], # react agent 接收訊息方式\n",
    "        \"history\": state[\"history\"],\n",
    "    }\n",
    "\n",
    "async def replan_step(state: PlanExecute):\n",
    "    # 過濾掉state中不需要的欄位\n",
    "    temp_state = state.copy()\n",
    "    temp_state.pop(\"history\")\n",
    "\n",
    "    output = await replanner.ainvoke(temp_state)\n",
    "    if isinstance(output.action, Response):\n",
    "        state[\"history\"].append((\"Replanner\", output.action.response))\n",
    "        return {\n",
    "            \"response\": output.action.response,\n",
    "            \"history\": state[\"history\"],\n",
    "        }\n",
    "    else:\n",
    "        state[\"history\"].append((\"Replanner\", output.action.steps))\n",
    "        return {\n",
    "            \"plan\": output.action.steps,\n",
    "            \"history\": state[\"history\"],\n",
    "        }\n",
    "\n",
    "async def solve_step(state: PlanExecute):\n",
    "    print(\"history:\")\n",
    "    print(state[\"history\"])\n",
    "    response = await solver.ainvoke({\"user_input\": state[\"input\"], \"planning_history\": state[\"history\"]})\n",
    "    return {\"response\": response.content, \"history\": state[\"history\"]}\n",
    "\n",
    "def should_end(state: PlanExecute):\n",
    "    if \"response\" in state and state[\"response\"]:\n",
    "        return \"solver\"\n",
    "    else:\n",
    "        return \"executor\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "workflow = StateGraph(PlanExecute)\n",
    "\n",
    "workflow.add_node(\"planner\", plan_step)\n",
    "workflow.add_node(\"executor\", execute_step)\n",
    "workflow.add_node(\"replanner\", replan_step)\n",
    "workflow.add_node(\"solver\", solve_step)\n",
    "\n",
    "workflow.add_edge(START, \"planner\")\n",
    "workflow.add_edge(\"planner\", \"executor\")\n",
    "workflow.add_edge(\"executor\", \"replanner\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"replanner\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_end,\n",
    "    [\"executor\", \"solver\"],\n",
    ")\n",
    "workflow.add_edge(\"solver\", END)\n",
    "\n",
    "app = workflow.compile() # This compiles it into a LangChain Runnable, meaning you can use it as you would any other runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "\n",
    "# display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 0\n",
    "\n",
    "with open(\"Outputs/execution_chat_log.txt\", \"w\") as f:\n",
    "    f.write(\"\")\n",
    "\n",
    "def write_to_chat_log(content):\n",
    "    with open(\"Outputs/execution_chat_log.txt\", \"a\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "# Who is the headmaster of National Central University in Taiwan?\n",
    "# Summarize the content of the 111 Academic Affairs Regulations.\n",
    "# Please help me fill out the leave application on the school website.\n",
    "config = {\"recursion_limit\": 30}\n",
    "inputs = {\n",
    "    \"input\": \"Who is the headmaster of National Central University in Taiwan?\",\n",
    "    \"history\": [], # 初始化儲存History的list\n",
    "}\n",
    "write_to_chat_log(f\"User Query:\\n{inputs['input']}\\n\\n\")\n",
    "\n",
    "# tool_dict[\"create_browser\"].invoke(input=None)\n",
    "\n",
    "async for event in app.astream(inputs, config=config):\n",
    "    for agent, state in event.items():\n",
    "        if agent != \"__end__\":\n",
    "            write_to_chat_log(f\"{agent}:\\n\")\n",
    "            # ! Jupyter Notebook 裡使用 global sequence 會報錯，需要使用 nest_asyncio\n",
    "            # global sequence\n",
    "            # sequence += 1\n",
    "            # write_to_chat_log(f\"{sequence}. {agent}:\\n\")\n",
    "\n",
    "            for key, value in state.items():\n",
    "                if (key != \"history\"):\n",
    "                    write_to_chat_log(f\"{key}: {value}\\n\")\n",
    "            \n",
    "            write_to_chat_log(\"\\n\")\n",
    "\n",
    "# del tools.selenium_controller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import create_react_agent_with_yaml\n",
    "\n",
    "# * 根據使用者輸入和計畫制定生成評估標準\n",
    "critic = create_react_agent_with_yaml(\"Critic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = critic.invoke({\"messages\": [(\"user\", \"Please evaluate the performance of execution team.\")]})\n",
    "\n",
    "# # 暫存評估標準，之後儲存到state內交給evaluator\n",
    "# with open(\"Docs/evaluation_rubric.txt\", \"w\") as f:\n",
    "#     f.write(f\"{response['messages'][-1].content}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看調用工具情形\n",
    "# for message in response[\"messages\"]:\n",
    "#     print(message)\n",
    "#     if not message.content:\n",
    "#         for item in message:\n",
    "#             print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import create_react_agent_with_yaml\n",
    "\n",
    "# * 根據評估者提供的評估框架和評估執行團隊的任務執行成效\n",
    "evaluator = create_react_agent_with_yaml(\"Evaluator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('Docs/evaluation_rubric.txt', 'r') as file:\n",
    "#     evaluation_rubric = file.read()\n",
    "\n",
    "# response = evaluator.invoke({\"messages\": [(\"user\", evaluation_rubric)]})\n",
    "\n",
    "# # 暫存評估結果，之後儲存到state內交給analyzer\n",
    "# with open(\"evaluation_result.txt\", \"w\") as f:\n",
    "#     f.write(f\"{response['messages'][-1].content}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 查看調用工具情形\n",
    "# for message in response[\"messages\"]:\n",
    "#     print(message)\n",
    "#     if not message.content:\n",
    "#         for item in message:\n",
    "#             print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "analyzer_llm_config = agents_parameter[\"Analyzer\"][\"llm_config\"]\n",
    "analyzer_system_prompt = agents_parameter[\"Analyzer\"][\"prompt\"]\n",
    "\n",
    "analyzer_llm = ChatOpenAI(model=analyzer_llm_config[\"model\"], temperature=analyzer_llm_config[\"temperature\"])\n",
    "analyzer_prompt = ChatPromptTemplate.from_template(analyzer_system_prompt)\n",
    "\n",
    "analyzer = analyzer_prompt | analyzer_llm\n",
    "\n",
    "print(\"analyzer_llm_config:\")\n",
    "for key, value in analyzer_llm_config.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(\"analyzer_system_prompt: \\n\" + analyzer_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"Docs/evaluation_result.txt\") as file:\n",
    "#     evaluation_result = file.read()\n",
    "\n",
    "# response = analyzer.invoke({\"evaluation_result\": evaluation_result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Graph State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "class Evaluation(TypedDict):\n",
    "    input: str\n",
    "    rubric: str\n",
    "    result: str\n",
    "    judgment: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agent Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def critic_step(state: Evaluation):\n",
    "    response = await critic.ainvoke({\"messages\": [(\"user\", state[\"input\"])]})\n",
    "    state[\"rubric\"] = response[\"messages\"][-1].content # 儲存評估標準到state內\n",
    "    return {\n",
    "        \"rubric\": state[\"rubric\"],\n",
    "    }\n",
    "\n",
    "async def evaluator_step(state: Evaluation):\n",
    "    response = await evaluator.ainvoke({\"messages\": [(\"user\", state[\"rubric\"])]})\n",
    "    state[\"result\"] = response[\"messages\"][-1].content # 儲存評估結果到state內\n",
    "    return {\n",
    "        \"result\": state[\"result\"],\n",
    "    }\n",
    "\n",
    "async def analyzer_step(state: Evaluation):\n",
    "    response = await analyzer.ainvoke({\"evaluation_result\": state[\"result\"]})\n",
    "    state[\"judgment\"] = response.content # 儲存分析結果到state內\n",
    "    return {\n",
    "        \"judgment\": state[\"judgment\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "evaluation_workflow = StateGraph(Evaluation)\n",
    "\n",
    "evaluation_workflow.add_node(\"critic\", critic_step)\n",
    "evaluation_workflow.add_node(\"evaluator\", evaluator_step)\n",
    "evaluation_workflow.add_node(\"analyzer\", analyzer_step)\n",
    "\n",
    "evaluation_workflow.add_edge(START, \"critic\")\n",
    "evaluation_workflow.add_edge(\"critic\", \"evaluator\")\n",
    "evaluation_workflow.add_edge(\"evaluator\", END)\n",
    "# evaluation_workflow.add_edge(\"evaluator\", \"analyzer\")\n",
    "# evaluation_workflow.add_edge(\"analyzer\", END)\n",
    "\n",
    "evaluation_app = evaluation_workflow.compile() # This compiles it into a LangChain Runnable, meaning you can use it as you would any other runnable\n",
    "\n",
    "display(Image(evaluation_app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 0\n",
    "\n",
    "with open(\"evaluation_chat_log.txt\", \"w\") as f:\n",
    "    f.write(\"\")\n",
    "\n",
    "def write_to_chat_log(content):\n",
    "    with open(\"evaluation_chat_log.txt\", \"a\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "# Please evaluate the performance of execution team.\n",
    "config = {\"recursion_limit\": 50}\n",
    "inputs = {\n",
    "    \"input\": \"Please evaluate the performance of execution team.\",\n",
    "}\n",
    "write_to_chat_log(f\"Evaluation Query:\\n{inputs['input']}\\n\\n\")\n",
    "\n",
    "async for event in evaluation_app.astream(inputs, config=config):\n",
    "    for agent, state in event.items():\n",
    "        if agent != \"__end__\":\n",
    "            write_to_chat_log(f\"{agent}:\\n\")\n",
    "            # ! Jupyter Notebook 裡使用 global sequence 會報錯，需要使用 nest_asyncio\n",
    "            # global sequence\n",
    "            # sequence += 1\n",
    "            # write_to_chat_log(f\"{sequence}. {agent}:\\n\")\n",
    "\n",
    "            for key, value in state.items():\n",
    "                if (key != \"history\"):\n",
    "                    write_to_chat_log(f\"{key}: {value}\\n\")\n",
    "            \n",
    "            write_to_chat_log(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolution Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "analyzer_llm_config = agents_parameter[\"Analyzer\"][\"llm_config\"]\n",
    "analyzer_system_prompt = agents_parameter[\"Analyzer\"][\"prompt\"]\n",
    "\n",
    "analyzer_llm = ChatOpenAI(model=analyzer_llm_config[\"model\"], temperature=analyzer_llm_config[\"temperature\"])\n",
    "analyzer_prompt = ChatPromptTemplate.from_template(analyzer_system_prompt)\n",
    "\n",
    "analyzer = analyzer_prompt | analyzer_llm\n",
    "\n",
    "print(\"analyzer_llm_config:\")\n",
    "for key, value in analyzer_llm_config.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(\"analyzer_system_prompt: \\n\" + analyzer_system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph_03_28_25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
