{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY_SELF\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This app is using the following tool:\n",
      "none\n",
      "website_info_retriever\n",
      "website_links_crawler\n",
      "website_reader\n",
      "pdf_reader\n",
      "create_browser\n",
      "screen_shot\n",
      "navigate\n",
      "get_html_content\n",
      "input_text_with_label\n",
      "input_text_with_name\n",
      "click_button_with_text\n",
      "click_input_with_label\n",
      "click_input_with_value\n",
      "click_input_with_id\n",
      "select_dropdown_option\n",
      "click_span_with_aria_label\n",
      "upload_file_with_id\n",
      "read_user_input_and_plan\n",
      "read_execution_chat_log\n",
      "read_execution_team_agents_prompt\n",
      "read_evaluation_result\n"
     ]
    }
   ],
   "source": [
    "from tools import Tools\n",
    "\n",
    "tools = Tools()\n",
    "tool_dict = tools.tool_dict\n",
    "\n",
    "print(\"This app is using the following tool:\")\n",
    "for tool in tool_dict:\n",
    "    print(tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Agent Parameter (yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# ! 注意yaml檔案版本\n",
    "with open('agents_parameter.yaml', 'r', encoding=\"utf-8\") as file:\n",
    "    agents_parameter = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "planner_llm_config:\n",
      "model: gpt-4o\n",
      "temperature: 0\n",
      "planner_system_prompt: \n",
      "You are a Planner Agent in an LLM-based multi-agent system designed to make plans for Executor Agents to follow in order to fulfill user requests by gathering information or operating systems related to National Central University.\n",
      "\n",
      "Your job is to generate clear, logical, and actionable step-by-step plans that guide other agents to fulfill the user's request. Each plan step should include:\n",
      "  - A brief explanation of what the step aims to accomplish\n",
      "  - A clear description of what needs to be found or processed\n",
      "  - An output placeholder (e.g., #E1, #E2, etc.) for use in later steps\n",
      "\n",
      "You must use variables like #E1, #E2, etc., to represent intermediate results that can be referenced in later steps. Make sure each step builds clearly upon previous steps. The final step should return the content that most accurately and completely fulfills the user's request.\n",
      "\n",
      "Please use the following reasoning framework **as a flexible guide**, not as a fixed template. You should adjust the number and content of the steps according to the user's task type and needs.\n",
      "\n",
      "Step 0. Begin by analyzing the user's request to determine the type of task it represents (e.g., information retrieval, system operation, form submission, etc.).\n",
      "  #E0 = [Identified task type]\n",
      "\n",
      "Then proceed with a plan structure that is suitable for #E0. Here are two reference workflows you may adapt:\n",
      "\n",
      "# TODO 帶入之前構思過的任務執行思維\n",
      "---  \n",
      "**If #E0 == \"information retrieval\"**, a typical plan may look like:\n",
      "  Step 1. Identify the most relevant website from pre-defined website information database. #E1 = [URL]\n",
      "  Step 2. Read the content of the selected site. #E2 = [Content of #E1]\n",
      "  Step 3. Evaluate whether the content is sufficient. #E3 = [Sufficiency judgment]\n",
      "  Step 4. If needed, find in-page hyperlinks to better sources. #E4 = [List of links]\n",
      "  Step 5. Follow the best link and read new content. #E5 = [New page content]\n",
      "  Step 6. Extract final information. #E6 = [Final answer]\n",
      "\n",
      "---  \n",
      "**If #E0 == \"system operation\"**, a typical plan may include:\n",
      "  Step 1. Identify the system to interact with. #E1 = [System name]\n",
      "  Step 2. Determine authentication requirements. #E2 = [Login/auth info]\n",
      "  Step 3. Clarify the operation goal. #E3 = [Target operation]\n",
      "  Step 4. Locate the UI or API to perform the action. #E4 = [Action location]\n",
      "  Step 5. Specify inputs and procedures. #E5 = [Interaction steps]\n",
      "  Step 6. Perform the operation and capture the result. #E6 = [Outcome]\n",
      "  Step 7. Verify success and define any follow-up. #E7 = [Verification result]\n",
      "\n",
      "---  \n",
      "\n",
      "These templates are not meant to be copied verbatim. Instead, **use them as flexible guides** to build your own plan suited to the actual user request.\n",
      "\n",
      "Do not include step 0 in the output. The first step should begin at Step 1. Each step should be concise and explicitly executable by an Executor Agent.\n",
      "\n",
      "User Input:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    \"\"\"Plan to follow in future\"\"\"\n",
    "\n",
    "    steps: List[str] = Field(\n",
    "        description=\"different steps to follow, should be in sorted order\"\n",
    "    )\n",
    "\n",
    "planner_llm_config = agents_parameter[\"Planner\"][\"llm_config\"]\n",
    "planner_system_prompt = agents_parameter[\"Planner\"][\"prompt\"]\n",
    "\n",
    "planner_llm = ChatOpenAI(model=planner_llm_config[\"model\"], temperature=planner_llm_config[\"temperature\"])\n",
    "planner_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", planner_system_prompt),\n",
    "        (\"placeholder\", \"{user_input}\"), # placeholer 用來動態嵌入使用者輸入的訊息\n",
    "    ]\n",
    ")\n",
    "\n",
    "planner = planner_prompt | planner_llm.with_structured_output(Plan) # 限制使用特定模板回答問題\n",
    "\n",
    "print(\"planner_llm_config:\")\n",
    "for key, value in planner_llm_config.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(\"planner_system_prompt: \\n\" + planner_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = planner.invoke({\"user_input\": [(\"user\", \"Summarize the content of the 111 Academic Affairs Regulations.\")]})\n",
    "# for step in response.steps:\n",
    "#     print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = planner.invoke({\"user_input\": [(\"user\", \"Please help me fill out the leave application on the school website.\")]})\n",
    "# for step in response.steps:\n",
    "#     print(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executor_llm_config:\n",
      "model: gpt-4o\n",
      "temperature: None\n",
      "Executor_prompt: \n",
      "You are an Executor Agent in a multi-agent system designed to assist users in finding and understanding information from school websites.\n",
      "You will receive structured step-by-step plans generated by a Planner Agent. Each step includes a short description, an action to take, and a variable name to store the result (e.g., #E1 = ...). Your job is to correctly interpret each instruction and execute the most appropriate tool to complete the action.\n",
      "\n",
      "Tools available to you:\n",
      "  - website_info_retriever: Retrieves metadata or structured information about a given school website from a pre-built database.\n",
      "  - website_reader: Extracts the main textual content from a given web page URL.\n",
      "  - website_links_crawler: Extracts and returns a list of hyperlinks from a given web page.\n",
      "  - pdf_reader: Extracts and returns the text content of a PDF file located at a given URL.\n",
      "\n",
      "Execution Rules:\n",
      "  1. Carefully analyze each task instruction and identify which tool is most suitable.\n",
      "  2. Use only the tool necessary to fulfill the specific action.\n",
      "  3. Execute one instruction at a time and return the result in a format that other agents (like the Planner or Evaluator) can understand.\n",
      "  4. Preserve variable naming (e.g., #E1, #E2) to help with chaining between steps.\n",
      "  5. If a task input is unclear or invalid, return an error message with an explanation.\n",
      "  6. When you identify high-confidence internal links such as “President”, “Administration”, or “Leadership”, you may follow the link immediately without waiting for replanning, unless the plan explicitly asks you to stop.\n",
      "\n",
      "Notice:\n",
      "  - You must translate the user input into Traditional Chinese when you are using the website_info_retriever tool.\n",
      "\n",
      "Based on the tool's output, generate the response that best meets the objective of current plan step.\n",
      "\n",
      "Executor_tool_list: \n",
      "website_info_retriever\n",
      "website_links_crawler\n",
      "website_reader\n",
      "pdf_reader\n",
      "Executor_llm_config:\n",
      "model: gpt-4o\n",
      "temperature: None\n",
      "Executor_prompt: \n",
      "You are an Executor Agent in a multi-agent system designed to assist users in finding and understanding information from school websites.\n",
      "You will receive structured step-by-step plans generated by a Planner Agent. Each step includes a short description, an action to take, and a variable name to store the result (e.g., #E1 = ...). Your job is to correctly interpret each instruction and execute the most appropriate tool to complete the action.\n",
      "\n",
      "Tools available to you:\n",
      "  - website_info_retriever: Retrieves metadata or structured information about a given school website from a pre-built database.\n",
      "  - website_reader: Extracts the main textual content from a given web page URL.\n",
      "  - website_links_crawler: Extracts and returns a list of hyperlinks from a given web page.\n",
      "  - pdf_reader: Extracts and returns the text content of a PDF file located at a given URL.\n",
      "\n",
      "Execution Rules:\n",
      "  1. Carefully analyze each task instruction and identify which tool is most suitable.\n",
      "  2. Use only the tool necessary to fulfill the specific action.\n",
      "  3. Execute one instruction at a time and return the result in a format that other agents (like the Planner or Evaluator) can understand.\n",
      "  4. Preserve variable naming (e.g., #E1, #E2) to help with chaining between steps.\n",
      "  5. If a task input is unclear or invalid, return an error message with an explanation.\n",
      "  6. When you identify high-confidence internal links such as “President”, “Administration”, or “Leadership”, you may follow the link immediately without waiting for replanning, unless the plan explicitly asks you to stop.\n",
      "\n",
      "Notice:\n",
      "  - You must translate the user input into Traditional Chinese when you are using the website_info_retriever tool.\n",
      "\n",
      "Based on the tool's output, generate the response that best meets the objective of current plan step.\n",
      "\n",
      "Executor_tool_list: \n",
      "website_info_retriever\n",
      "website_links_crawler\n",
      "website_reader\n",
      "pdf_reader\n"
     ]
    }
   ],
   "source": [
    "from agents import create_react_agent_with_yaml\n",
    "\n",
    "executor = create_react_agent_with_yaml(\"Executor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 國立中央大學 校長\n",
      "---\n",
      "link:  https://ncusec.ncu.edu.tw/preselection/\n",
      "page_content: \n",
      " 網站標題: 校長遴選專區\n",
      "簡介: 國立中央大學的第九任校長遴選專區提供公告訊息、相關法規、委員名單、表單下載及聯絡資訊。根據最新公告，蕭述三教授已獲教育部同意聘任為校長，並於2024年10月30日正式上任。遴選過程中，包括候選人治校理念說明會和投票結果的相關會議紀錄均已公開。聯絡人為陳敏茲小姐及吳秋萍組長，聯絡電話及校址也已提供。\n",
      "---\n",
      "link:  https://osa.ncu.edu.tw/news_article.php?event_id=3101/news.php?event_category_no=1\n",
      "page_content: \n",
      " 網站標題: 行政\n",
      "簡介: 這篇網頁內容是關於國立中央大學學務處的各個部門及其服務，特別是生活輔導組的活動公告。公告提到了一場名為「宿舍導師講座」的講座，將於2024年12月13日（星期五）舉行，時間為18:30至20:30，地點在女14舍藝文空間。講者是李健榮博士，將探討畢業後的生涯選擇和自主學習的影響。參加者可獲得2小時的生活知能，並符合獎助學金申請的時數要求。聯絡人為胡硯芬，提供了聯絡電話和電子郵件。活動的短網址也提供了，方便查看詳情。\n",
      "---\n",
      "link:  https://osa.ncu.edu.tw/news_article.php?event_id=3108/news.php?event_category_no=1\n",
      "page_content: \n",
      " 網站標題: 行政\n",
      "簡介: 這段內容介紹了國立中央大學學務處及其各個組織的相關信息，包括生活輔導、諮商輔導、課外活動、服務學習、住宿、衛生保健、職涯發展及原住民族學生資源中心等。公告中提到大一週會及各院週會的安排，時間及地點，以及講座的主題和講者。週會將於2025年2月5日公告，並提供了報名網址及相關Q&A鏈接。此外，還列出了不同學院的週會日程及地點，並附上學務處的聯絡信息。\n",
      "---\n",
      "link:  https://www.ncu.edu.tw/tw/events/show.php?num=18789\n",
      "page_content: \n",
      " 網站標題: 本校附屬中壢高級中學第四任校長遴選專區\n",
      "簡介: 國立中央大學的公告專區提供有關中壢高級中學第四任校長遴選的信息。公告發布於2025年2月10日，由人事室負責，類別為徵才，瀏覽人次達2449次。網站還提供了多項重要連結和功能，包括校曆、校園地圖及教學單位等資訊。使用者需注意瀏覽器的兼容性，推薦使用Chrome、Firefox或Microsoft Edge，並在網站上使用Cookie以提升使用體驗。\n",
      "---\n",
      "link:  https://pdc.adm.ncu.edu.tw/sir_meeting.asp\n",
      "page_content: \n",
      " 網站標題: 主管會議\n",
      "簡介: 國立中央大學的教務處網站提供了有關教務處的各項資訊，包括教務長室的簡介、最新消息、職責、會議紀錄及相關章則。此外，網頁還設有系所評鑑專區和網路辦公室的連結，並強調學生的四大基本素養。網站的聯絡地址位於桃園市中壢區，並提供了電話和傳真資訊。建議使用Chrome、Firefox或Microsoft Edge瀏覽，以獲得最佳顯示效果。\n",
      "---\n",
      "link:  http://www.ncu.edu.tw\n",
      "page_content: \n",
      " 網站標題: 中央大學\n",
      "簡介: 內容提到「國立中央大學」兩次。\n",
      "---\n",
      "link:  https://pdc.adm.ncu.edu.tw/rule_note3.asp\n",
      "page_content: \n",
      " 網站標題: 歷年第二專長\n",
      "簡介: 國立中央大學的教務處網站提供多項功能和資訊，包括教務法規、招生資訊、註冊、課務、教學發展等。網站內有最新消息、教務處簡介、校曆、各學年度的教務章則彙編，以及新生專區和系所評鑑相關資料。此外，網站還提供選課系統、歷屆考古題、學生證專區等資源。網站建議使用Chrome、Firefox或Microsoft Edge瀏覽，以獲得最佳顯示效果。聯絡資訊包括地址和電話等。\n",
      "---\n",
      "link:  https://www.ncu.edu.tw/tw/pages/index.php?num=245\n",
      "page_content: \n",
      " 網站標題: 教職員\n",
      "簡介: 這段內容是關於國立中央大學的教職員專區，提供網站導航、行政業務、教學服務、校園生活等資訊。網站提醒用戶其瀏覽器不支援JavaScript，並提供了字型大小調整、列印及返回上一頁的快捷鍵。內容包括校曆、校園地圖、重要連結及聯絡資訊等。網站使用Cookie以提升使用體驗，並要求用戶同意Cookie的使用。最後，網站建議使用Chrome、Firefox或Microsoft Edge瀏覽，以獲得最佳顯示效果。\n",
      "---\n",
      "link:  https://pdc.adm.ncu.edu.tw/#/subindex1.asp\n",
      "page_content: \n",
      " 網站標題: 教務長室\n",
      "簡介: 國立中央大學的教務處網站提供了多項服務和最新公告，包括招生資訊、註冊及課務相關事宜，以及教學發展活動。網站上列出了一些最近的公告，例如研究所甄試錄取生的入學注意事項、課程停修申請的時間、以及各類教學增能工作坊和競賽的報名訊息。此外，網站還包含了聯絡資訊、隱私權政策和網站安全政策等內容。使用者需確保瀏覽器支持JavaScript以正常使用網站功能。\n",
      "---\n",
      "link:  https://osa.ncu.edu.tw/news_article.php?event_id=3101/index.php\n",
      "page_content: \n",
      " 網站標題: 首頁\n",
      "簡介: 網頁內容主要介紹了國立中央大學學務處的各個組織及其功能，並發布了一則演講公告。公告的主題是「宿舍導師講座」，將於2024年12月13日舉行，演講者為李健榮博士，將討論人生的選擇及自主學習的影響。活動時間為晚上6:30至8:30，地點在女14舍藝文空間，參加者可獲得2小時的生活知能認證，並且符合申請宿舍學習獎助學金的要求。聯絡人為胡硯芬，提供了聯絡電話和電子郵件資訊。\n",
      "---\n",
      "content='Who is the headmaster of National Central University in Taiwan?' additional_kwargs={} response_metadata={} id='fbd94324-6caa-4aa0-9d69-b42f18c862d4'\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_QNS88GREFXzqB4fnNnagZZpm', 'function': {'arguments': '{\"query\":\"國立中央大學 校長\"}', 'name': 'website_info_retriever'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 540, 'total_tokens': 564, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_726d488742', 'id': 'chatcmpl-BMAfZeoaM4EpJn67ftPq5Z3ITc59q', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-73baedc4-17da-4b87-b718-7ff1f1639ea0-0' tool_calls=[{'name': 'website_info_retriever', 'args': {'query': '國立中央大學 校長'}, 'id': 'call_QNS88GREFXzqB4fnNnagZZpm', 'type': 'tool_call'}] usage_metadata={'input_tokens': 540, 'output_tokens': 24, 'total_tokens': 564, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "content='link: https://ncusec.ncu.edu.tw/preselection/\\n網站標題: 校長遴選專區\\n簡介: 國立中央大學的第九任校長遴選專區提供公告訊息、相關法規、委員名單、表單下載及聯絡資訊。根據最新公告，蕭述三教授已獲教育部同意聘任為校長，並於2024年10月30日正式上任。遴選過程中，包括候選人治校理念說明會和投票結果的相關會議紀錄均已公開。聯絡人為陳敏茲小姐及吳秋萍組長，聯絡電話及校址也已提供。\\n---\\nlink: https://osa.ncu.edu.tw/news_article.php?event_id=3101/news.php?event_category_no=1\\n網站標題: 行政\\n簡介: 這篇網頁內容是關於國立中央大學學務處的各個部門及其服務，特別是生活輔導組的活動公告。公告提到了一場名為「宿舍導師講座」的講座，將於2024年12月13日（星期五）舉行，時間為18:30至20:30，地點在女14舍藝文空間。講者是李健榮博士，將探討畢業後的生涯選擇和自主學習的影響。參加者可獲得2小時的生活知能，並符合獎助學金申請的時數要求。聯絡人為胡硯芬，提供了聯絡電話和電子郵件。活動的短網址也提供了，方便查看詳情。\\n---\\nlink: https://osa.ncu.edu.tw/news_article.php?event_id=3108/news.php?event_category_no=1\\n網站標題: 行政\\n簡介: 這段內容介紹了國立中央大學學務處及其各個組織的相關信息，包括生活輔導、諮商輔導、課外活動、服務學習、住宿、衛生保健、職涯發展及原住民族學生資源中心等。公告中提到大一週會及各院週會的安排，時間及地點，以及講座的主題和講者。週會將於2025年2月5日公告，並提供了報名網址及相關Q&A鏈接。此外，還列出了不同學院的週會日程及地點，並附上學務處的聯絡信息。\\n---\\nlink: https://www.ncu.edu.tw/tw/events/show.php?num=18789\\n網站標題: 本校附屬中壢高級中學第四任校長遴選專區\\n簡介: 國立中央大學的公告專區提供有關中壢高級中學第四任校長遴選的信息。公告發布於2025年2月10日，由人事室負責，類別為徵才，瀏覽人次達2449次。網站還提供了多項重要連結和功能，包括校曆、校園地圖及教學單位等資訊。使用者需注意瀏覽器的兼容性，推薦使用Chrome、Firefox或Microsoft Edge，並在網站上使用Cookie以提升使用體驗。\\n---\\nlink: https://pdc.adm.ncu.edu.tw/sir_meeting.asp\\n網站標題: 主管會議\\n簡介: 國立中央大學的教務處網站提供了有關教務處的各項資訊，包括教務長室的簡介、最新消息、職責、會議紀錄及相關章則。此外，網頁還設有系所評鑑專區和網路辦公室的連結，並強調學生的四大基本素養。網站的聯絡地址位於桃園市中壢區，並提供了電話和傳真資訊。建議使用Chrome、Firefox或Microsoft Edge瀏覽，以獲得最佳顯示效果。\\n---\\nlink: http://www.ncu.edu.tw\\n網站標題: 中央大學\\n簡介: 內容提到「國立中央大學」兩次。\\n---\\nlink: https://pdc.adm.ncu.edu.tw/rule_note3.asp\\n網站標題: 歷年第二專長\\n簡介: 國立中央大學的教務處網站提供多項功能和資訊，包括教務法規、招生資訊、註冊、課務、教學發展等。網站內有最新消息、教務處簡介、校曆、各學年度的教務章則彙編，以及新生專區和系所評鑑相關資料。此外，網站還提供選課系統、歷屆考古題、學生證專區等資源。網站建議使用Chrome、Firefox或Microsoft Edge瀏覽，以獲得最佳顯示效果。聯絡資訊包括地址和電話等。\\n---\\nlink: https://www.ncu.edu.tw/tw/pages/index.php?num=245\\n網站標題: 教職員\\n簡介: 這段內容是關於國立中央大學的教職員專區，提供網站導航、行政業務、教學服務、校園生活等資訊。網站提醒用戶其瀏覽器不支援JavaScript，並提供了字型大小調整、列印及返回上一頁的快捷鍵。內容包括校曆、校園地圖、重要連結及聯絡資訊等。網站使用Cookie以提升使用體驗，並要求用戶同意Cookie的使用。最後，網站建議使用Chrome、Firefox或Microsoft Edge瀏覽，以獲得最佳顯示效果。\\n---\\nlink: https://pdc.adm.ncu.edu.tw/#/subindex1.asp\\n網站標題: 教務長室\\n簡介: 國立中央大學的教務處網站提供了多項服務和最新公告，包括招生資訊、註冊及課務相關事宜，以及教學發展活動。網站上列出了一些最近的公告，例如研究所甄試錄取生的入學注意事項、課程停修申請的時間、以及各類教學增能工作坊和競賽的報名訊息。此外，網站還包含了聯絡資訊、隱私權政策和網站安全政策等內容。使用者需確保瀏覽器支持JavaScript以正常使用網站功能。\\n---\\nlink: https://osa.ncu.edu.tw/news_article.php?event_id=3101/index.php\\n網站標題: 首頁\\n簡介: 網頁內容主要介紹了國立中央大學學務處的各個組織及其功能，並發布了一則演講公告。公告的主題是「宿舍導師講座」，將於2024年12月13日舉行，演講者為李健榮博士，將討論人生的選擇及自主學習的影響。活動時間為晚上6:30至8:30，地點在女14舍藝文空間，參加者可獲得2小時的生活知能認證，並且符合申請宿舍學習獎助學金的要求。聯絡人為胡硯芬，提供了聯絡電話和電子郵件資訊。\\n---\\n' name='website_info_retriever' id='bd68ac4f-4b41-448c-bea0-a73a5f82cb86' tool_call_id='call_QNS88GREFXzqB4fnNnagZZpm'\n",
      "content='The current headmaster of National Central University in Taiwan is Professor Hsiao Shu-San (蕭述三教授), who is set to officially take office on October 30, 2024.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 2196, 'total_tokens': 2239, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_726d488742', 'id': 'chatcmpl-BMAfbh8tFQnLIrDnxLltdYa0ClRBN', 'finish_reason': 'stop', 'logprobs': None} id='run-1b5be9af-5826-4694-bf83-33338a8361f3-0' usage_metadata={'input_tokens': 2196, 'output_tokens': 43, 'total_tokens': 2239, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = executor.invoke({\"messages\": [(\"user\", \"Who is the headmaster of National Central University in Taiwan?\")]})\n",
    "for message in response[\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = executor.invoke({\"messages\": [(\"user\", \"Please help me fill out the leave application on https://cis.ncu.edu.tw/iNCU/stdAffair/leaveRequest.\")]})\n",
    "# for message in response[\"messages\"]:\n",
    "#     print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replanner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replanner_model: gpt-4o\n",
      "replanner_prompt: \n",
      "You are a Replanner Agent in a multi-agent system designed to assist users in finding and understanding information from school websites.\n",
      "For the given objective, come up with a simple step by step plan. \\\n",
      "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
      "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
      "\n",
      "Your objective was this:\n",
      "{input}\n",
      "\n",
      "Your original plan was this:\n",
      "{plan}\n",
      "\n",
      "You have currently done the following steps:\n",
      "{past_steps}\n",
      "\n",
      "If the original website or page appears insufficient (e.g., missing relevant info after one or two visits), consider redirecting the search to more general, authoritative sources—like the university's official homepage—or directly scanning for keywords in navigation items (e.g., \"President\", \"About\", \"Administration\", \"Leadership\").\n",
      "\n",
      "Update your plan accordingly. If no more steps are needed and you can return to the user, then respond with that. Otherwise, only include new steps that still NEED to be done to reach the final answer. **Do not return previously completed steps as part of the plan.**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "class Response(BaseModel):\n",
    "    \"\"\"Response to user.\"\"\"\n",
    "\n",
    "    response: str\n",
    "\n",
    "\n",
    "class Act(BaseModel):\n",
    "    \"\"\"Action to perform.\"\"\"\n",
    "\n",
    "    action: Union[Response, Plan] = Field(\n",
    "        description=\"Action to perform. If you want to respond to user, use Response.\"\n",
    "        \"If you need to further use tools to get the answer, use Plan.\"\n",
    "    )\n",
    "\n",
    "replanner_model = agents_parameter[\"Replanner\"][\"model\"]\n",
    "replanner_system_prompt = f\"{agents_parameter['Replanner']['prompt']}\"\n",
    "\n",
    "replanner_llm = ChatOpenAI(model=replanner_model) # ! Replanner需要使用gpt-4o才不會一直call tools\n",
    "replanner_prompt = ChatPromptTemplate.from_template(replanner_system_prompt)\n",
    "\n",
    "replanner = replanner_prompt | replanner_llm.with_structured_output(Act) # 限制使用特定模板回答問題\n",
    "\n",
    "print(\"replanner_model: \" + replanner_model)\n",
    "print(\"replanner_prompt: \\n\" + replanner_system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver_model: gpt-4o-mini\n",
      "solver_system_prompt: \n",
      "You are a Solver Agent in a multi-agent system that helps users find and understand information from school websites.\n",
      "\n",
      "You will receive:\n",
      "  - The original user request\n",
      "  - A list of past steps that have been completed\n",
      "  - The latest available information retrieved by other agents\n",
      "\n",
      "Your task is to:\n",
      "  1. Review all available information.\n",
      "  2. Determine whether the current information is sufficient to answer the user's request.\n",
      "  3. If it is sufficient, generate a clear and helpful response that directly addresses the user's request.\n",
      "  4. If it is not sufficient, explain what information is still missing and suggest what to do next.\n",
      "\n",
      "Be concise, accurate, and helpful. Your response will be shown directly to the user, so make sure it is complete and easy to understand.\n",
      "\n",
      "Inputs:\n",
      "  - User request: {user_input}\n",
      "  - Planning History: {planning_history}\n",
      "\n",
      "Based on the above, please generate the best possible response to fulfill the user's need.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "solver_model = agents_parameter[\"Solver\"][\"model\"]\n",
    "solver_system_prompt = agents_parameter[\"Solver\"][\"prompt\"]\n",
    "\n",
    "solver_llm = ChatOpenAI(model=solver_model)\n",
    "solver_prompt = ChatPromptTemplate.from_template(solver_system_prompt)\n",
    "\n",
    "solver = solver_prompt | solver_llm\n",
    "\n",
    "print(\"solver_model: \" + solver_model)\n",
    "print(\"solver_system_prompt: \\n\" + solver_system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Graph State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, Tuple, Any\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class PlanExecute(TypedDict):\n",
    "    input: str\n",
    "    plan: List[str]\n",
    "    past_steps: Annotated[List[Tuple], operator.add]\n",
    "    response: str\n",
    "    history: List[Tuple[str, Any]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agent Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def plan_step(state: PlanExecute):\n",
    "    plan = await planner.ainvoke({\"user_input\": [(\"user\", state[\"input\"])]}) # 對應到planner system prompt中的{user_input}\n",
    "    state[\"history\"].append((\"Planner\", plan.steps)) # 將plan的步驟加入history中\n",
    "\n",
    "    return {\n",
    "        \"plan\": plan.steps,\n",
    "        \"history\": state[\"history\"],\n",
    "    }\n",
    "\n",
    "async def execute_step(state: PlanExecute):\n",
    "    plan = state[\"plan\"]\n",
    "    plan_str = \"\\n\".join(f\"{i+1}. {step}\" for i, step in enumerate(plan))\n",
    "    task = plan[0]\n",
    "    task_formatted = f\"\"\"For the following plan:\n",
    "{plan_str}\\n\\nYou are tasked with executing step {1}, {task}.\"\"\"\n",
    "    agent_response = await executor.ainvoke({\"messages\": [(\"user\", task_formatted)]}) # react agent 用 messages 方式接收訊息\n",
    "    state[\"history\"].append((\"Executor\", (task, agent_response[\"messages\"][-1].content)))\n",
    "\n",
    "    return {\n",
    "        \"past_steps\": [(task, agent_response[\"messages\"][-1].content)], # react agent 接收訊息方式\n",
    "        \"history\": state[\"history\"],\n",
    "    }\n",
    "\n",
    "async def replan_step(state: PlanExecute):\n",
    "    # 過濾掉state中不需要的欄位\n",
    "    temp_state = state.copy()\n",
    "    temp_state.pop(\"history\")\n",
    "\n",
    "    output = await replanner.ainvoke(temp_state)\n",
    "    if isinstance(output.action, Response):\n",
    "        state[\"history\"].append((\"Replanner\", output.action.response))\n",
    "        return {\n",
    "            \"response\": output.action.response,\n",
    "            \"history\": state[\"history\"],\n",
    "        }\n",
    "    else:\n",
    "        state[\"history\"].append((\"Replanner\", output.action.steps))\n",
    "        return {\n",
    "            \"plan\": output.action.steps,\n",
    "            \"history\": state[\"history\"],\n",
    "        }\n",
    "\n",
    "async def solve_step(state: PlanExecute):\n",
    "    print(\"history:\")\n",
    "    print(state[\"history\"])\n",
    "    response = await solver.ainvoke({\"user_input\": state[\"input\"], \"planning_history\": state[\"history\"]})\n",
    "    return {\"response\": response.content, \"history\": state[\"history\"]}\n",
    "\n",
    "def should_end(state: PlanExecute):\n",
    "    if \"response\" in state and state[\"response\"]:\n",
    "        return \"solver\"\n",
    "    else:\n",
    "        return \"executor\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "workflow = StateGraph(PlanExecute)\n",
    "\n",
    "workflow.add_node(\"planner\", plan_step)\n",
    "workflow.add_node(\"executor\", execute_step)\n",
    "workflow.add_node(\"replanner\", replan_step)\n",
    "workflow.add_node(\"solver\", solve_step)\n",
    "\n",
    "workflow.add_edge(START, \"planner\")\n",
    "workflow.add_edge(\"planner\", \"executor\")\n",
    "workflow.add_edge(\"executor\", \"replanner\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"replanner\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_end,\n",
    "    [\"executor\", \"solver\"],\n",
    ")\n",
    "workflow.add_edge(\"solver\", END)\n",
    "\n",
    "app = workflow.compile() # This compiles it into a LangChain Runnable, meaning you can use it as you would any other runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "\n",
    "# display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 0\n",
    "\n",
    "with open(\"Outputs/execution_chat_log.txt\", \"w\") as f:\n",
    "    f.write(\"\")\n",
    "\n",
    "def write_to_chat_log(content):\n",
    "    with open(\"Outputs/execution_chat_log.txt\", \"a\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "# Who is the headmaster of National Central University in Taiwan?\n",
    "# Summarize the content of the 111 Academic Affairs Regulations.\n",
    "# Please help me fill out the leave application on the school website.\n",
    "config = {\"recursion_limit\": 30}\n",
    "inputs = {\n",
    "    \"input\": \"Who is the headmaster of National Central University in Taiwan?\",\n",
    "    \"history\": [], # 初始化儲存History的list\n",
    "}\n",
    "write_to_chat_log(f\"User Query:\\n{inputs['input']}\\n\\n\")\n",
    "\n",
    "# tool_dict[\"create_browser\"].invoke(input=None)\n",
    "\n",
    "async for event in app.astream(inputs, config=config):\n",
    "    for agent, state in event.items():\n",
    "        if agent != \"__end__\":\n",
    "            write_to_chat_log(f\"{agent}:\\n\")\n",
    "            # ! Jupyter Notebook 裡使用 global sequence 會報錯，需要使用 nest_asyncio\n",
    "            # global sequence\n",
    "            # sequence += 1\n",
    "            # write_to_chat_log(f\"{sequence}. {agent}:\\n\")\n",
    "\n",
    "            for key, value in state.items():\n",
    "                if (key != \"history\"):\n",
    "                    write_to_chat_log(f\"{key}: {value}\\n\")\n",
    "            \n",
    "            write_to_chat_log(\"\\n\")\n",
    "\n",
    "# del tools.selenium_controller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import create_react_agent_with_yaml\n",
    "\n",
    "# * 根據使用者輸入和計畫制定生成評估標準\n",
    "critic = create_react_agent_with_yaml(\"Critic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = critic.invoke({\"messages\": [(\"user\", \"Please evaluate the performance of execution team.\")]})\n",
    "\n",
    "# # 暫存評估標準，之後儲存到state內交給evaluator\n",
    "# with open(\"Docs/evaluation_rubric.txt\", \"w\") as f:\n",
    "#     f.write(f\"{response['messages'][-1].content}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看調用工具情形\n",
    "# for message in response[\"messages\"]:\n",
    "#     print(message)\n",
    "#     if not message.content:\n",
    "#         for item in message:\n",
    "#             print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import create_react_agent_with_yaml\n",
    "\n",
    "# * 根據評估者提供的評估框架和評估執行團隊的任務執行成效\n",
    "evaluator = create_react_agent_with_yaml(\"Evaluator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('Docs/evaluation_rubric.txt', 'r') as file:\n",
    "#     evaluation_rubric = file.read()\n",
    "\n",
    "# response = evaluator.invoke({\"messages\": [(\"user\", evaluation_rubric)]})\n",
    "\n",
    "# # 暫存評估結果，之後儲存到state內交給analyzer\n",
    "# with open(\"evaluation_result.txt\", \"w\") as f:\n",
    "#     f.write(f\"{response['messages'][-1].content}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 查看調用工具情形\n",
    "# for message in response[\"messages\"]:\n",
    "#     print(message)\n",
    "#     if not message.content:\n",
    "#         for item in message:\n",
    "#             print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "analyzer_llm_config = agents_parameter[\"Analyzer\"][\"llm_config\"]\n",
    "analyzer_system_prompt = agents_parameter[\"Analyzer\"][\"prompt\"]\n",
    "\n",
    "analyzer_llm = ChatOpenAI(model=analyzer_llm_config[\"model\"], temperature=analyzer_llm_config[\"temperature\"])\n",
    "analyzer_prompt = ChatPromptTemplate.from_template(analyzer_system_prompt)\n",
    "\n",
    "analyzer = analyzer_prompt | analyzer_llm\n",
    "\n",
    "print(\"analyzer_llm_config:\")\n",
    "for key, value in analyzer_llm_config.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(\"analyzer_system_prompt: \\n\" + analyzer_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"Docs/evaluation_result.txt\") as file:\n",
    "#     evaluation_result = file.read()\n",
    "\n",
    "# response = analyzer.invoke({\"evaluation_result\": evaluation_result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Graph State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "class Evaluation(TypedDict):\n",
    "    input: str\n",
    "    rubric: str\n",
    "    result: str\n",
    "    judgment: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agent Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def critic_step(state: Evaluation):\n",
    "    response = await critic.ainvoke({\"messages\": [(\"user\", state[\"input\"])]})\n",
    "    state[\"rubric\"] = response[\"messages\"][-1].content # 儲存評估標準到state內\n",
    "    return {\n",
    "        \"rubric\": state[\"rubric\"],\n",
    "    }\n",
    "\n",
    "async def evaluator_step(state: Evaluation):\n",
    "    response = await evaluator.ainvoke({\"messages\": [(\"user\", state[\"rubric\"])]})\n",
    "    state[\"result\"] = response[\"messages\"][-1].content # 儲存評估結果到state內\n",
    "    return {\n",
    "        \"result\": state[\"result\"],\n",
    "    }\n",
    "\n",
    "async def analyzer_step(state: Evaluation):\n",
    "    response = await analyzer.ainvoke({\"evaluation_result\": state[\"result\"]})\n",
    "    state[\"judgment\"] = response.content # 儲存分析結果到state內\n",
    "    return {\n",
    "        \"judgment\": state[\"judgment\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "evaluation_workflow = StateGraph(Evaluation)\n",
    "\n",
    "evaluation_workflow.add_node(\"critic\", critic_step)\n",
    "evaluation_workflow.add_node(\"evaluator\", evaluator_step)\n",
    "evaluation_workflow.add_node(\"analyzer\", analyzer_step)\n",
    "\n",
    "evaluation_workflow.add_edge(START, \"critic\")\n",
    "evaluation_workflow.add_edge(\"critic\", \"evaluator\")\n",
    "evaluation_workflow.add_edge(\"evaluator\", END)\n",
    "# evaluation_workflow.add_edge(\"evaluator\", \"analyzer\")\n",
    "# evaluation_workflow.add_edge(\"analyzer\", END)\n",
    "\n",
    "evaluation_app = evaluation_workflow.compile() # This compiles it into a LangChain Runnable, meaning you can use it as you would any other runnable\n",
    "\n",
    "display(Image(evaluation_app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 0\n",
    "\n",
    "with open(\"evaluation_chat_log.txt\", \"w\") as f:\n",
    "    f.write(\"\")\n",
    "\n",
    "def write_to_chat_log(content):\n",
    "    with open(\"evaluation_chat_log.txt\", \"a\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "# Please evaluate the performance of execution team.\n",
    "config = {\"recursion_limit\": 50}\n",
    "inputs = {\n",
    "    \"input\": \"Please evaluate the performance of execution team.\",\n",
    "}\n",
    "write_to_chat_log(f\"Evaluation Query:\\n{inputs['input']}\\n\\n\")\n",
    "\n",
    "async for event in evaluation_app.astream(inputs, config=config):\n",
    "    for agent, state in event.items():\n",
    "        if agent != \"__end__\":\n",
    "            write_to_chat_log(f\"{agent}:\\n\")\n",
    "            # ! Jupyter Notebook 裡使用 global sequence 會報錯，需要使用 nest_asyncio\n",
    "            # global sequence\n",
    "            # sequence += 1\n",
    "            # write_to_chat_log(f\"{sequence}. {agent}:\\n\")\n",
    "\n",
    "            for key, value in state.items():\n",
    "                if (key != \"history\"):\n",
    "                    write_to_chat_log(f\"{key}: {value}\\n\")\n",
    "            \n",
    "            write_to_chat_log(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolution Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "analyzer_llm_config = agents_parameter[\"Analyzer\"][\"llm_config\"]\n",
    "analyzer_system_prompt = agents_parameter[\"Analyzer\"][\"prompt\"]\n",
    "\n",
    "analyzer_llm = ChatOpenAI(model=analyzer_llm_config[\"model\"], temperature=analyzer_llm_config[\"temperature\"])\n",
    "analyzer_prompt = ChatPromptTemplate.from_template(analyzer_system_prompt)\n",
    "\n",
    "analyzer = analyzer_prompt | analyzer_llm\n",
    "\n",
    "print(\"analyzer_llm_config:\")\n",
    "for key, value in analyzer_llm_config.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(\"analyzer_system_prompt: \\n\" + analyzer_system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph_03_28_25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
