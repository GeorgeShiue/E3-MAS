{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planner_llm_config:\n",
      "model: gpt-4.1-mini\n",
      "temperature: 0\n",
      "\n",
      "Planner_prompt: \n",
      "You are a Planner Agent in an LLM-based multi-agent system designed to make plans for Executor Agents to follow in order to fulfill user requests by gathering information or operating systems related to National Central University.\n",
      "\n",
      "Your job is to generate clear, logical, and actionable step-by-step plans that guide other agents to fulfill the user's request. Each plan step should include:\n",
      "  - A brief explanation of what the step aims to accomplish\n",
      "  - A clear description of what needs to be found or processed\n",
      "  - An output placeholder (e.g., #E1, #E2, etc.) for use in later steps\n",
      "\n",
      "You must use variables like #E1, #E2, etc., to represent intermediate results that can be referenced in later steps, and ensure each step builds upon the previous one. The final plan should be concise, clearly structured, and executable by an Executor Agent.\n",
      "\n",
      "Use the following reasoning framework **as a flexible guide** and adjust steps based on the user's task type and needs.\n",
      "\n",
      "Step 0. Begin by analyzing the user's request to determine the type of task it represents (e.g., information retrieval, system operation, form submission, etc.).\n",
      "  #E0 = [Identified task type]\n",
      "\n",
      "Then proceed with a plan structure that is suitable for #E0. Here are two reference workflows you may adapt:\n",
      "\n",
      "---  \n",
      "**If #E0 == \"information retrieval\"**, a typical plan may include:\n",
      "  Step 1. Identify the most relevant website to user's query from website information database. #E1 = [URL]\n",
      "  Step 2. Read the content of the selected site. #E2 = [Content of #E1]\n",
      "  Step 3. Evaluate whether the content is sufficient to fulfill the user's query. #E3 = [Sufficiency judgment]\n",
      "  Step 4. If the content is not sufficient, find in-page hyperlinks to better sources. #E4 = [List of links]\n",
      "  Step 5. If the content is not sufficient, follow the link that is the most relevant to user's query and read new content. #E5 = [New page content]\n",
      "  Step 6. IF the information is sufficient to fulfill the user's query, extract final information. #E6 = [Final answer]\n",
      "\n",
      "---  \n",
      "**If #E0 == \"system operation\"**, a typical plan (e.g. full plan of leave application) may include:\n",
      "  Step 1. function_name: 'navigate_with_url', parameters: '{{\"url\":\"https://cis.ncu.edu.tw/iNCU/stdAffair/leaveRequest\"}}' E1 = [Response form the web operation tools]\n",
      "  Step 2. function_name: 'input_text_with_label', parameters: '{{\"label_text\":\"Account\",\"text\":\"user_account\",\"privacy\":\"Account\"}}' E2 = [Response form the web operation tools]\n",
      "  Step 3. function_name: 'input_text_with_label', parameters: '{{\"label_text\":\"Password\",\"text\":\"user_password\",\"privacy\":\"Password\"}}' E3 = [Response form the web operation tools]\n",
      "  Step 4. function_name: 'click_button_with_text', parameters: '{{\"text\":\"Login to Portal\"}}' E4 = [Response form the web operation tools]\n",
      "  Step 5. function_name: 'click_button_with_text', parameters: '{{\"text\":\"Go to\"}}'E5 = [Response form the web operation tools]\n",
      "  Step 6. function_name: 'click_button_with_text', parameters: '{{\"text\":\"申請\"}}' E6 = [Response form the web operation tools]\n",
      "\n",
      "  Notice: \n",
      "    You should not change the order, the content, and the expect result of the steps in the above plan.\n",
      "    You should add an additional step to read the HTML of the current webpage before performing each of the steps listed above.\n",
      "    read the HTML of the current webpage step: function_name: 'get_html_content', parameters: '{{}}' E? = [Response form the web operation tools]\n",
      "\n",
      "---  \n",
      "\n",
      "These templates are examples to **guide** your planning based on the actual user request.\n",
      "\n",
      "Do not include step 0 in the output. The first step should begin at Step 1. Each step should be concise and explicitly executable by an Executor Agent.\n",
      "\n",
      "User Input:\n",
      "\n",
      "\n",
      "Executor_llm_config:\n",
      "model: gpt-4.1-mini\n",
      "temperature: 0\n",
      "\n",
      "Executor_prompt: \n",
      "You are an Executor Agent in a multi-agent system designed to assist users in finding and understanding information from school websites.\n",
      "You will receive structured step-by-step plans generated by a Planner Agent. Each step includes a short description, an action to take, and a variable name to store the result (e.g., #E1 = ...). Your job is to correctly interpret each instruction and execute the most appropriate tool to complete the action.\n",
      "\n",
      "Tools available to you:\n",
      "  - website_info_retriever: Retrieves metadata or structured information about a given school website from a pre-built database.\n",
      "  - website_reader: Extracts the main textual content from a given web page URL.\n",
      "  - website_links_crawler: Extracts and returns a list of hyperlinks from a given web page.\n",
      "  - pdf_reader: Extracts and returns the text content of a PDF file located at a given URL.\n",
      "\n",
      "Execution Rules:\n",
      "  1. Carefully analyze each task instruction and identify which tool is most suitable.\n",
      "  2. Use only the tool necessary to fulfill the specific action.\n",
      "  3. Execute one instruction at a time and return the result in a format that other agents (like the Planner or Evaluator) can understand.\n",
      "  4. Preserve variable naming (e.g., #E1, #E2) to help with chaining between steps.\n",
      "  5. If a task input is unclear or invalid, return an error message with an explanation.\n",
      "\n",
      "Notice:\n",
      "  - You must translate the user input into Traditional Chinese when you are using the website_info_retriever tool.\n",
      "\n",
      "Based on the tool's output, generate the response that best meets the objective of current plan step.\n",
      "\n",
      "\n",
      "Executor_tool_list: \n",
      "website_info_retriever\n",
      "website_reader\n",
      "website_links_crawler\n",
      "pdf_reader\n",
      "\n",
      "Web Executor_llm_config:\n",
      "model: gpt-4.1-mini\n",
      "temperature: 0\n",
      "\n",
      "Web Executor_prompt: \n",
      "You are an Executor Agent in a multi-agent system designed to assist users in finding and understanding information from school websites.\n",
      "You will receive structured step-by-step plans generated by a Planner Agent. Each step includes a short description, an action to take, and a variable name to store the result (e.g., #E1 = ...). Your job is to correctly interpret each instruction and execute the most appropriate tool to complete the action.\n",
      "\n",
      "Tools available to you:\n",
      "  - navigate_with_url: Navigates to a specified URL.\n",
      "  - get_html_content: Retrieves the HTML content of a given URL.\n",
      "  - input_text_with_label: Inputs text into a form field identified by a label.\n",
      "  - input_text_with_name: Inputs text into a form field identified by a name attribute.\n",
      "  - click_button_with_text: Clicks a button identified by its text.\n",
      "  - click_input_with_label: Clicks an input field identified by a label.\n",
      "  - click_input_with_value: Clicks an input field identified by its value.\n",
      "  - click_input_with_id: Clicks an input field identified by its ID.\n",
      "  - select_dropdown_option: Selects an option from a dropdown menu.\n",
      "  - click_span_with_aria_label: Clicks a span element identified by its aria-label attribute.\n",
      "  - upload_file_with_id: Uploads a file to a form field identified by its ID.\n",
      "\n",
      "Execution Rules:\n",
      "  1. Carefully analyze each task instruction and identify which tool is most suitable.\n",
      "  2. Use only the tool necessary to fulfill the specific action.\n",
      "  3. Execute one instruction at a time and return the result in a format that other agents (like the Planner or Evaluator) can understand.\n",
      "  4. Preserve variable naming (e.g., #E1, #E2) to help with chaining between steps.\n",
      "  5. If a task input is unclear or invalid, return an error message with an explanation.\n",
      "\n",
      "Notice:\n",
      "  - You must translate the user input into Traditional Chinese when you are using the website_info_retriever tool.\n",
      "\n",
      "Based on the tool's output, generate the response that best meets the objective of current plan step.\n",
      "\n",
      "\n",
      "Web Executor_tool_list: \n",
      "navigate_with_url\n",
      "get_html_content\n",
      "input_text_with_label\n",
      "input_text_with_name\n",
      "click_button_with_text\n",
      "click_input_with_label\n",
      "click_input_with_value\n",
      "click_input_with_id\n",
      "select_dropdown_option\n",
      "click_span_with_aria_label\n",
      "upload_file_with_id\n",
      "\n",
      "Replanner_llm_config:\n",
      "model: gpt-4.1-mini\n",
      "temperature: 0\n",
      "\n",
      "Replanner_prompt: \n",
      "You are a Replanner Agent in a multi-agent system designed to assist users in finding and understanding information from school websites.\n",
      "For the given objective, come up with a simple step by step plan. \\\n",
      "This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n",
      "The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n",
      "\n",
      "Your objective was this:\n",
      "{input}\n",
      "\n",
      "Your original plan was this:\n",
      "{plan}\n",
      "\n",
      "You have currently done the following steps:\n",
      "{past_steps}\n",
      "\n",
      "If the original website lacks sufficient information (e.g., after one or two visits), redirect the search to more authoritative sources such as the university homepage, or scan navigation items for keywords.\n",
      "\n",
      "Update your plan accordingly. If no more steps are needed and you can return to the user, then respond with that. Otherwise, only include new steps that still NEED to be done to reach the final answer. **Do not return previously completed steps as part of the plan.**\n",
      "\n",
      "\n",
      "Solver_llm_config:\n",
      "model: gpt-4.1-mini\n",
      "\n",
      "Solver_prompt: \n",
      "You are a Solver Agent in a multi-agent system that helps users find and understand information from school websites.\n",
      "\n",
      "You will receive:\n",
      "  - The original user request\n",
      "  - A list of past steps that have been completed\n",
      "  - The latest available information retrieved by other agents\n",
      "\n",
      "Your task is to:\n",
      "  1. Review all available information.\n",
      "  2. Determine whether the current information is sufficient to answer the user's request.\n",
      "  3. If it is sufficient, generate a clear and helpful response that directly addresses the user's request.\n",
      "  4. If it is not sufficient, explain what information is still missing and suggest what to do next.\n",
      "\n",
      "Be concise, accurate, and helpful. Your response will be shown directly to the user, so make sure it is complete and easy to understand.\n",
      "\n",
      "Inputs:\n",
      "  - User request: {user_input}\n",
      "  - Planning History: {planning_history}\n",
      "\n",
      "Based on the above, please generate the best possible response to fulfill the user's need.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from agent import ExecutionAgent\n",
    "\n",
    "execution_agent = ExecutionAgent()\n",
    "\n",
    "planner = execution_agent.planner\n",
    "# executor = execution_agents.executor\n",
    "executor = execution_agent.web_executor # 測試 web executor\n",
    "replanner = execution_agent.replanner\n",
    "solver = execution_agent.solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = planner.invoke({\"user_input\": [(\"user\", \"Please help me apply leave application.\")]})\n",
    "# for step in response.steps:\n",
    "#     print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating container for user_id 1130...\n",
      "Container suspicious_jang created on port 10050\n",
      "Container created for user_id 1130 on port 10050\n",
      "Connected to Selenium container for user_id 1130 on port 10050\n",
      "Browser for user_id 1130 navigated to https://cis.ncu.edu.tw/iNCU/stdAffair/leaveRequest\n",
      "Screenshot saved for user_id 1130 at screenshots/website_screenshot_1.png\n",
      "#E1 = 已成功導覽至中興大學請假系統頁面 https://cis.ncu.edu.tw/iNCU/stdAffair/leaveRequest 。請問接下來需要我執行什麼操作？\n",
      "Execution time: 4.112503528594971 seconds\n",
      "Cleaning up all containers...\n",
      "Found 1 containers.\n",
      "Container suspicious_jang has been stopped and removed.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "execution_agent.web_operation_tool.create_browser()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "response = executor.invoke({\"messages\": [(\"user\", \"Step 1. function_name: 'navigate_with_url', parameters: '{\\\"url\\\":\\\"https://cis.ncu.edu.tw/iNCU/stdAffair/leaveRequest\\\"}'\")]})\n",
    "print(response[\"messages\"][-1].content)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "\n",
    "execution_agent.web_operation_tool.selenium_controller.clean_containers() # *selenium controller解構子有問題，必須runtime內清除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Step 1. function_name: \\'navigate_with_url\\', parameters: \\'{\"url\":\"https://cis.ncu.edu.tw/iNCU/stdAffair/leaveRequest\"}\\'', additional_kwargs={}, response_metadata={}, id='fc8362c6-15b2-4476-bd9d-ee1669cc8f63'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_EToVGKRhJVaoC20Vm4iRxAWi', 'function': {'arguments': '{\"url\":\"https://cis.ncu.edu.tw/iNCU/stdAffair/leaveRequest\"}', 'name': 'navigate_with_url'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 928, 'total_tokens': 959, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_38647f5e19', 'id': 'chatcmpl-BOjM7Y5oJSKdVxk1yBFu7tpZlIgmJ', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-9a2bbdb2-94c2-4a44-ac0f-d82da67309b8-0', tool_calls=[{'name': 'navigate_with_url', 'args': {'url': 'https://cis.ncu.edu.tw/iNCU/stdAffair/leaveRequest'}, 'id': 'call_EToVGKRhJVaoC20Vm4iRxAWi', 'type': 'tool_call'}], usage_metadata={'input_tokens': 928, 'output_tokens': 31, 'total_tokens': 959, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='null', name='navigate_with_url', id='11a1d336-6f39-4a68-8f6d-19002fbb938a', tool_call_id='call_EToVGKRhJVaoC20Vm4iRxAWi'), AIMessage(content='#E1 = 已成功導覽至中興大學請假系統頁面 https://cis.ncu.edu.tw/iNCU/stdAffair/leaveRequest 。請問接下來需要我執行什麼操作？', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 968, 'total_tokens': 1020, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_38647f5e19', 'id': 'chatcmpl-BOjMAeYdxCb5oScenJ6Z6KpbrAxRq', 'finish_reason': 'stop', 'logprobs': None}, id='run-ff05c5e0-4e63-44b7-a927-48499483a4f0-0', usage_metadata={'input_tokens': 968, 'output_tokens': 52, 'total_tokens': 1020, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Graph State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, Tuple, Any\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class PlanExecute(TypedDict):\n",
    "    input: str\n",
    "    plan: List[str]\n",
    "    past_steps: Annotated[List[Tuple], operator.add]\n",
    "    response: str\n",
    "    history: List[Tuple[str, Any]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agent Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def plan_step(state: PlanExecute):\n",
    "    plan = await planner.ainvoke({\"user_input\": [(\"user\", state[\"input\"])]}) # 對應到planner system prompt中的{user_input}\n",
    "    state[\"history\"].append((\"Planner\", plan.steps)) # 將plan的步驟加入history中\n",
    "\n",
    "    return {\n",
    "        \"plan\": plan.steps,\n",
    "        \"history\": state[\"history\"],\n",
    "    }\n",
    "\n",
    "async def execute_step(state: PlanExecute):\n",
    "    plan = state[\"plan\"]\n",
    "    plan_str = \"\\n\".join(f\"{i+1}. {step}\" for i, step in enumerate(plan))\n",
    "    task = plan[0]\n",
    "    task_formatted = f\"\"\"For the following plan:\n",
    "{plan_str}\\n\\nYou are tasked with executing step {1}, {task}.\"\"\"\n",
    "    agent_response = await executor.ainvoke({\"messages\": [(\"user\", task_formatted)]}) # react agent 用 messages 方式接收訊息\n",
    "    state[\"history\"].append((\"Executor\", (task, agent_response[\"messages\"][-1].content)))\n",
    "\n",
    "    return {\n",
    "        \"past_steps\": [(task, agent_response[\"messages\"][-1].content)], # react agent 接收訊息方式\n",
    "        \"history\": state[\"history\"],\n",
    "    }\n",
    "\n",
    "async def replan_step(state: PlanExecute):\n",
    "    # 過濾掉state中不需要的欄位\n",
    "    temp_state = state.copy()\n",
    "    temp_state.pop(\"history\")\n",
    "\n",
    "    output = await replanner.ainvoke(temp_state)\n",
    "    if isinstance(output.action, execution_agent.Response):\n",
    "        state[\"history\"].append((\"Replanner\", output.action.response))\n",
    "        return {\n",
    "            \"response\": output.action.response,\n",
    "            \"history\": state[\"history\"],\n",
    "        }\n",
    "    else:\n",
    "        state[\"history\"].append((\"Replanner\", output.action.steps))\n",
    "        return {\n",
    "            \"plan\": output.action.steps,\n",
    "            \"history\": state[\"history\"],\n",
    "        }\n",
    "\n",
    "async def solve_step(state: PlanExecute):\n",
    "    print(\"history:\")\n",
    "    print(state[\"history\"])\n",
    "    response = await solver.ainvoke({\"user_input\": state[\"input\"], \"planning_history\": state[\"history\"]})\n",
    "    return {\"response\": response.content, \"history\": state[\"history\"]}\n",
    "\n",
    "def should_end(state: PlanExecute):\n",
    "    if \"response\" in state and state[\"response\"]:\n",
    "        return \"solver\"\n",
    "    else:\n",
    "        return \"executor\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "execution_workflow = StateGraph(PlanExecute)\n",
    "\n",
    "execution_workflow.add_node(\"planner\", plan_step)\n",
    "execution_workflow.add_node(\"executor\", execute_step)\n",
    "execution_workflow.add_node(\"replanner\", replan_step)\n",
    "execution_workflow.add_node(\"solver\", solve_step)\n",
    "\n",
    "execution_workflow.add_edge(START, \"planner\")\n",
    "execution_workflow.add_edge(\"planner\", \"executor\")\n",
    "execution_workflow.add_edge(\"executor\", \"replanner\")\n",
    "execution_workflow.add_conditional_edges(\n",
    "    \"replanner\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_end,\n",
    "    [\"executor\", \"solver\"],\n",
    ")\n",
    "execution_workflow.add_edge(\"solver\", END)\n",
    "\n",
    "execution_app = execution_workflow.compile() # This compiles it into a LangChain Runnable, meaning you can use it as you would any other runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from PIL import Image as PILImage\n",
    "from io import BytesIO\n",
    "\n",
    "graph_bytes = execution_app.get_graph(xray=True).draw_mermaid_png()\n",
    "\n",
    "# output_file_path = \"test.jpg\"\n",
    "# with BytesIO(graph_bytes) as byte_stream:\n",
    "#     image = PILImage.open(byte_stream)\n",
    "#     image.save(output_file_path, format=\"PNG\")\n",
    "\n",
    "display(Image(graph_bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import nest_asyncio\n",
    "# nest_asyncio.apply()\n",
    "\n",
    "# start_time = time.time()\n",
    "# result = tool_dict[\"website_links_crawler\"].invoke({\"link\": \"https://pdc.adm.ncu.edu.tw/#&panel1-1\"})\n",
    "# # website_links_crawler(\"https://www.ncu.edu.tw/tw/\")\n",
    "\n",
    "\n",
    "\n",
    "# end_time = time.time()\n",
    "# execution_time = end_time - start_time\n",
    "\n",
    "# print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import time\n",
    "\n",
    "with open(\"Outputs/execution_chat_log.txt\", \"w\") as f:\n",
    "    f.write(\"\")\n",
    "\n",
    "def write_to_chat_log(content):\n",
    "    with open(\"Outputs/execution_chat_log.txt\", \"a\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "# Who is the headmaster of National Central University in Taiwan?\n",
    "# Summarize the content of the 111 Academic Affairs Regulations.\n",
    "# Please help me gather information related to scholarship applications.\n",
    "# Please help me fill out the leave application on the school website.\n",
    "config = {\"recursion_limit\": 30}\n",
    "inputs = {\n",
    "    \"input\": \"Please help me gather information related to scholarship applications.\",\n",
    "    \"history\": [], # 初始化儲存History的list\n",
    "}\n",
    "write_to_chat_log(f\"User Query:\\n{inputs['input']}\\n\\n\")\n",
    "\n",
    "# tool_dict[\"create_browser\"].invoke(input=None)\n",
    "\n",
    "nest_asyncio.apply()\n",
    "start_time = time.time()\n",
    "async for event in execution_app.astream(inputs, config=config):\n",
    "    for agent, state in event.items():\n",
    "        if agent != \"__end__\":\n",
    "            write_to_chat_log(f\"{agent}:\\n\")\n",
    "\n",
    "            for key, value in state.items():\n",
    "                if (key != \"history\"):\n",
    "                    write_to_chat_log(f\"{key}: {value}\\n\")\n",
    "            \n",
    "            write_to_chat_log(\"\\n\")\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time} seconds\")\n",
    "# del tools.selenium_controller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import create_react_agent_with_yaml\n",
    "\n",
    "# * 根據使用者輸入和計畫制定生成評估標準\n",
    "critic = create_react_agent_with_yaml(\"Critic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = critic.invoke({\"messages\": [(\"user\", \"Please evaluate the performance of execution team.\")]})\n",
    "\n",
    "# # 暫存評估標準，之後儲存到state內交給evaluator\n",
    "# with open(\"Docs/evaluation_rubric.txt\", \"w\") as f:\n",
    "#     f.write(f\"{response['messages'][-1].content}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看調用工具情形\n",
    "# for message in response[\"messages\"]:\n",
    "#     print(message)\n",
    "#     if not message.content:\n",
    "#         for item in message:\n",
    "#             print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import create_react_agent_with_yaml\n",
    "\n",
    "# * 根據評估者提供的評估框架和評估執行團隊的任務執行成效\n",
    "evaluator = create_react_agent_with_yaml(\"Evaluator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('Docs/evaluation_rubric.txt', 'r') as file:\n",
    "#     evaluation_rubric = file.read()\n",
    "\n",
    "# response = evaluator.invoke({\"messages\": [(\"user\", evaluation_rubric)]})\n",
    "\n",
    "# # 暫存評估結果，之後儲存到state內交給analyzer\n",
    "# with open(\"evaluation_result.txt\", \"w\") as f:\n",
    "#     f.write(f\"{response['messages'][-1].content}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 查看調用工具情形\n",
    "# for message in response[\"messages\"]:\n",
    "#     print(message)\n",
    "#     if not message.content:\n",
    "#         for item in message:\n",
    "#             print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Graph State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "class Evaluation(TypedDict):\n",
    "    input: str\n",
    "    rubric: str\n",
    "    result: str\n",
    "    judgment: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agent Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def critic_step(state: Evaluation):\n",
    "    response = await critic.ainvoke({\"messages\": [(\"user\", state[\"input\"])]})\n",
    "    state[\"rubric\"] = response[\"messages\"][-1].content # 儲存評估標準到state內\n",
    "    return {\n",
    "        \"rubric\": state[\"rubric\"],\n",
    "    }\n",
    "\n",
    "async def evaluator_step(state: Evaluation):\n",
    "    response = await evaluator.ainvoke({\"messages\": [(\"user\", state[\"rubric\"])]})\n",
    "    state[\"result\"] = response[\"messages\"][-1].content # 儲存評估結果到state內\n",
    "    return {\n",
    "        \"result\": state[\"result\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "evaluation_workflow = StateGraph(Evaluation)\n",
    "\n",
    "evaluation_workflow.add_node(\"critic\", critic_step)\n",
    "evaluation_workflow.add_node(\"evaluator\", evaluator_step)\n",
    "\n",
    "evaluation_workflow.add_edge(START, \"critic\")\n",
    "evaluation_workflow.add_edge(\"critic\", \"evaluator\")\n",
    "evaluation_workflow.add_edge(\"evaluator\", END)\n",
    "\n",
    "evaluation_app = evaluation_workflow.compile() # This compiles it into a LangChain Runnable, meaning you can use it as you would any other runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Image(evaluation_app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "with open(\"Outputs/evaluation_chat_log.txt\", \"w\") as f:\n",
    "    f.write(\"\")\n",
    "\n",
    "def write_to_chat_log(content):\n",
    "    with open(\"Outputs/evaluation_chat_log.txt\", \"a\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "# Please evaluate the performance of execution team.\n",
    "config = {\"recursion_limit\": 50}\n",
    "inputs = {\n",
    "    \"input\": \"Please evaluate the performance of execution team.\",\n",
    "}\n",
    "write_to_chat_log(f\"Evaluation Query:\\n{inputs['input']}\\n\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "async for event in evaluation_app.astream(inputs, config=config):\n",
    "    for agent, state in event.items():\n",
    "        if agent != \"__end__\":\n",
    "            write_to_chat_log(f\"{agent}:\\n\")\n",
    "\n",
    "            for key, value in state.items():\n",
    "                if (key != \"history\"):\n",
    "                    write_to_chat_log(f\"{key}: {value}\\n\")\n",
    "            \n",
    "            write_to_chat_log(\"\\n\")\n",
    "end_time = time.time()\n",
    "\n",
    "evaluation_time = end_time - start_time\n",
    "print(f\"Evaluation time: {evaluation_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolution Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# analyzer_llm_config = agents_parameter[\"Analyzer\"][\"llm_config\"]\n",
    "# analyzer_system_prompt = agents_parameter[\"Analyzer\"][\"prompt\"]\n",
    "\n",
    "# analyzer_llm = ChatOpenAI(model=analyzer_llm_config[\"model\"], temperature=analyzer_llm_config[\"temperature\"])\n",
    "# analyzer_prompt = ChatPromptTemplate.from_template(analyzer_system_prompt)\n",
    "\n",
    "# analyzer = analyzer_prompt | analyzer_llm\n",
    "\n",
    "# print(\"analyzer_llm_config:\")\n",
    "# for key, value in analyzer_llm_config.items():\n",
    "#     print(f\"{key}: {value}\")\n",
    "# print(\"analyzer_system_prompt: \\n\" + analyzer_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import create_react_agent_with_yaml\n",
    "\n",
    "analyzer = create_react_agent_with_yaml(\"Analyzer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = analyzer.invoke({\"messages\": [(\"user\", \"Please analyze the evaluation result of the execution team.\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import create_react_agent_with_yaml\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Optimization_Response(BaseModel):\n",
    "    \"\"\"Optimization response to user.\"\"\"\n",
    "    \n",
    "    updated_agent_system_prompt: str = Field(\n",
    "        description=\"The complete updated system prompt for the agent that is most responsible for the identified issue.\"\n",
    "    )\n",
    "\n",
    "prompt_optimizer = create_react_agent_with_yaml(\"Prompt Optimizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = \"\"\"\n",
    "analysis: All steps in the evaluation report were scored as Fully Met. There are some improvement suggestions mentioned, but none indicate clear underperformance or partial fulfillment of the task. Therefore, I will analyze the improvement suggestions to see if any step shows clear room for improvement that warrants responsibility attribution.\n",
    "\n",
    "Step 1: URL identification was appropriate; suggestion is to justify URL choice more clearly. This is a Planner-related improvement.\n",
    "\n",
    "Step 2: Content extraction was relevant; suggestion is to summarize content relevance explicitly. This relates to Executor's communication of results.\n",
    "\n",
    "Step 3: Sufficiency assessment was accurate; suggestion is to state criteria explicitly. This is a Planner responsibility to define assessment criteria.\n",
    "\n",
    "Step 4: Relevant links identified; suggestion to avoid non-functional links. This is an Executor detail in link selection.\n",
    "\n",
    "Step 5: Redirecting search was efficient; suggestion to document rationale earlier. This relates to Replanner's decision-making transparency.\n",
    "\n",
    "Step 6: Final extraction accurate; suggestion to include direct citation. This is Executor's presentation of results.\n",
    "\n",
    "Additional replanning steps: Effective replanning; suggestion to document decision-making more explicitly. This is Replanner responsibility.\n",
    "\n",
    "Summary of improvement suggestions:\n",
    "- Planner: Justify URL choice, state sufficiency criteria explicitly\n",
    "- Executor: Summarize content relevance, avoid non-functional links, include citations\n",
    "- Replanner: Document replanning decisions more explicitly\n",
    "\n",
    "None of these suggestions indicate failure or partial fulfillment, only room for clearer communication and documentation.\n",
    "\n",
    "Hence, no step shows clear underperformance. The overall task outcome was successful with all steps fully met.\n",
    "\n",
    "Final judgment:\n",
    "- No agent caused underperformance.\n",
    "- Minor improvements are distributed among Planner, Executor, and Replanner.\n",
    "- Since the plan was solid and execution was correct, and replanning was effective, the overall responsibility is balanced.\n",
    "- If forced to select the primary responsible agent for minor improvements, the Planner could be highlighted for improving clarity in plan justification and assessment criteria.\n",
    "\n",
    "---\n",
    "\n",
    "**Primary Responsible Agent**: Planner  \n",
    "**Justification for Final Attribution**: The Planner could improve by explicitly justifying URL choices and clearly stating sufficiency criteria, which would enhance clarity and reduce ambiguity in the execution process. These foundational improvements would benefit the entire workflow.  \n",
    "**Summary of Issues**: Minor suggestions for clearer documentation and communication in plan justification, content relevance assessment, and replanning rationale; no failures or partial completions.\"\"\"\n",
    "# response = prompt_optimizer.invoke({\"messages\": [(\"user\", f\"Analysis: \\n{analysis}\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Graph State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "class Evolution(TypedDict):\n",
    "    input: str\n",
    "    analysis: str\n",
    "    result: str\n",
    "    # updated_agent_system_prompt: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agent Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def analyze_step(state: Evolution):\n",
    "    response = await analyzer.ainvoke({\"messages\": [(\"user\", state[\"input\"])]})\n",
    "    return {\n",
    "        \"analysis\": response[\"messages\"][-1].content # 儲存分析結果到state內\n",
    "    }\n",
    "\n",
    "async def prompt_optimize_step(state: Evolution):\n",
    "    response = await prompt_optimizer.ainvoke({\"messages\": [(\"user\", state[\"analysis\"])]})\n",
    "    \n",
    "    return {\n",
    "        \"result\": response[\"messages\"][-1].content, # 儲存最終回覆到state內,\n",
    "        # \"updated_agent_system_prompt\": response[\"structured_response\"].updated_agent_system_prompt # 儲存更新過後的prompt到state內\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "evolution_workflow = StateGraph(Evolution)\n",
    "\n",
    "evolution_workflow.add_node(\"analyzer\", analyze_step)\n",
    "evolution_workflow.add_node(\"prompt_optimizer\", prompt_optimize_step)\n",
    "\n",
    "evolution_workflow.add_edge(START, \"analyzer\")\n",
    "evolution_workflow.add_edge(\"analyzer\", \"prompt_optimizer\")\n",
    "evolution_workflow.add_edge(\"prompt_optimizer\", END)\n",
    "\n",
    "evolution_app = evolution_workflow.compile() # This compiles it into a LangChain Runnable, meaning you can use it as you would any other runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(evolution_app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "with open(\"Outputs/evolution_chat_log.txt\", \"w\") as f:\n",
    "    f.write(\"\")\n",
    "\n",
    "def write_to_chat_log(content):\n",
    "    with open(\"Outputs/evolution_chat_log.txt\", \"a\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "# Please analyze the evaluation result of the execution team.\n",
    "config = {\"recursion_limit\": 50}\n",
    "inputs = {\n",
    "    \"input\": \"Please analyze the evaluation result of the execution team.\",\n",
    "}\n",
    "write_to_chat_log(f\"Evolution Query:\\n{inputs['input']}\\n\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "async for event in evolution_app.astream(inputs, config=config):\n",
    "    for agent, state in event.items():\n",
    "        if agent != \"__end__\":\n",
    "            write_to_chat_log(f\"{agent}:\\n\")\n",
    "\n",
    "            for key, value in state.items():\n",
    "                if (key != \"history\"):\n",
    "                    write_to_chat_log(f\"{key}: {value}\\n\")\n",
    "            \n",
    "            write_to_chat_log(\"\\n\")\n",
    "end_time = time.time()\n",
    "\n",
    "evolution_time = end_time - start_time\n",
    "print(f\"Evolution time: {evolution_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph_03_28_25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
